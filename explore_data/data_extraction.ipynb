{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. extract articel from XML file#######################################3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getopt\n",
    "import sys\n",
    "import xml.sax\n",
    "import lxml.sax\n",
    "import lxml.etree\n",
    "import re\n",
    "#defined a function for data extraction from Xml files\n",
    "def handleArticle(article, outFile):\n",
    "    termfrequencies = {}\n",
    "\n",
    "    # get text from article\n",
    "    text = lxml.etree.tostring(article, method=\"text\",encoding=\"unicode\").replace(\"?\",\" \").replace(\"\\n\",\" \").replace(\"\\t\",\" \") \n",
    "    # writing counts: <article id> <token>:<count> <token>:<count> ...\n",
    "    art_id = article.get(\"id\")\n",
    "    #print(art_id)\n",
    "    title = article.get(\"title\")\n",
    "    outFile.write(art_id + \"\\t\"+ title+ \" \"+ text + \"\\n\")\n",
    "class HyperpartisanNewsTFExtractor(xml.sax.ContentHandler):\n",
    "    def __init__(self, outFile):\n",
    "        xml.sax.ContentHandler.__init__(self)\n",
    "        self.outFile = outFile\n",
    "        self.lxmlhandler = \"undefined\"\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name != \"articles\":\n",
    "            if name == \"article\":\n",
    "                self.lxmlhandler = lxml.sax.ElementTreeContentHandler()\n",
    "\n",
    "            self.lxmlhandler.startElement(name, attrs)\n",
    "\n",
    "    def characters(self, data):\n",
    "        if self.lxmlhandler != \"undefined\":\n",
    "            self.lxmlhandler.characters(data)\n",
    "\n",
    "    def endElement(self, name):\n",
    "        if self.lxmlhandler != \"undefined\":\n",
    "            self.lxmlhandler.endElement(name)\n",
    "            if name == \"article\":\n",
    "                # pass to handleArticle function\n",
    "                handleArticle(self.lxmlhandler.etree.getroot(), self.outFile)\n",
    "                self.lxmlhandler = \"undefined\"                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from articles-training-20180831.xml\n",
    "with open(\"articles-20180831.txt\", 'w') as outFile:  #output name           \n",
    "    with open(\"articles-training-20180831.xml\") as inputRunFile: #input name\n",
    "        xml.sax.parse(inputRunFile, HyperpartisanNewsTFExtractor(outFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from articles-validation-20180831.xml\n",
    "with open(\"articles-20180831.txt\", 'a') as outFile:  #output name               \n",
    "    with open(\"articles-training-20180831.xml\") as inputRunFile: #input name\n",
    "        xml.sax.parse(inputRunFile, HyperpartisanNewsTFExtractor(outFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from articles-training-bypublisher-201801122.xml\n",
    "with open(\"articles-bypublisher-201801122.txt\", 'w') as outFile:  #output name               \n",
    "    with open(\"articles-training-bypublisher-201801122.xml\") as inputRunFile: #input name\n",
    "        xml.sax.parse(inputRunFile, HyperpartisanNewsTFExtractor(outFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from articles-validation-bypublisher-20181122.xml\n",
    "with open(\"articles-bypublisher-20181122.txt\", 'a') as outFile:  #output name               \n",
    "    with open(\"articles-validation-bypublisher-20181122.xml\") as inputRunFile: #input name\n",
    "        xml.sax.parse(inputRunFile, HyperpartisanNewsTFExtractor(outFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data from articles-training-byarticle-20181122.xml\n",
    "with open(\"articles-byarticle-20181122.txt\", 'w') as outFile:  #output name               \n",
    "    with open(\"articles-training-byarticle-20181122.xml\") as inputRunFile: #input name\n",
    "        xml.sax.parse(inputRunFile, HyperpartisanNewsTFExtractor(outFile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. extract labels ###############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from XML file\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "#import pandas as pd\n",
    "tree = ET.parse('ground-truth-training-20180831.xml')   #input name\n",
    "root = tree.getroot()\n",
    "# get labels and store in a plain text\n",
    "f = open(\"ground-truth-20180831.txt\", 'w')    #output name  \n",
    "for child in root:\n",
    "    f.write(child.attrib[\"id\"]+\"\\t\"+child.attrib[\"hyperpartisan\"]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from XML file\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "#import pandas as pd\n",
    "\n",
    "tree = ET.parse('ground-truth-validation-20180831.xml')   #input name\n",
    "root = tree.getroot()\n",
    "# get labels and store in a plain text\n",
    "f = open(\"ground-truth-20180831.txt\", 'a')    #output name  \n",
    "for child in root:\n",
    "    f.write(child.attrib[\"id\"]+\"\\t\"+child.attrib[\"hyperpartisan\"]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from XML file\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "tree = ET.parse('ground-truth-training-bypublisher-20181122.xml')   #input name\n",
    "root = tree.getroot()\n",
    "# get labels and store in a plain text\n",
    "f = open(\"ground-truth-20181122.txt\", 'w')    #output name  \n",
    "for child in root:\n",
    "    f.write(child.attrib[\"id\"]+\"\\t\"+child.attrib[\"hyperpartisan\"]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from XML file\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "tree = ET.parse('ground-truth-validation-bypublisher-20181122.xml')   #input name\n",
    "root = tree.getroot()\n",
    "# get labels and store in a plain text\n",
    "f = open(\"ground-truth-20181122.txt\", 'a')    #output name  \n",
    "for child in root:\n",
    "    f.write(child.attrib[\"id\"]+\"\\t\"+child.attrib[\"hyperpartisan\"]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels from XML file\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import collections\n",
    "import pandas as pd\n",
    "\n",
    "tree = ET.parse('ground-truth-byarticle-20181122.xml')   #input name\n",
    "root = tree.getroot()\n",
    "# get labels and store in a plain text\n",
    "f = open(\"ground-truth-20181122.txt\", 'a')    #output name  \n",
    "for child in root:\n",
    "    f.write(child.attrib[\"id\"]+\"\\t\"+child.attrib[\"hyperpartisan\"]+\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. read dataset from 1., generate a dectionary: {id:articel} and a id list ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles-20180831.txt (old version data)\n",
    "keys_old = []\n",
    "con_dic_old = {}\n",
    "with open(\"articles-20180831.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for i, item in enumerate(lines):\n",
    "        if item.startswith(\"article\"):\n",
    "            print(i)\n",
    "            continue\n",
    "        else:\n",
    "            keys_old.append(item.split(\"\\t\")[0])\n",
    "            idx = item.split(\"\\t\")[0].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            content = item.split(\"\\t\")[1].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            con_dic_old[idx] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    }
   ],
   "source": [
    "print(len(keys_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles-bypublisher-20181122.txt (new version data)\n",
    "keys_new = []\n",
    "con_dic_new = {}\n",
    "with open(\"articles-bypublisher-20181122.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for i, item in enumerate(lines):\n",
    "        if item.startswith(\"article\"):\n",
    "            continue\n",
    "        else:\n",
    "            keys_new.append(item.split(\"\\t\")[0])\n",
    "            idx = item.split(\"\\t\")[0].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            content = item.split(\"\\t\")[1].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "            con_dic_new[idx] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750000\n"
     ]
    }
   ],
   "source": [
    "print(len(keys_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000000\n"
     ]
    }
   ],
   "source": [
    "# get labels from ground-truth-20180831.txt (old version data)\n",
    "lab_old = []\n",
    "lab_dic_old = {}\n",
    "with open(\"ground-truth-20180831.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for item in lines:\n",
    "        lab_old.append(item.split(\"\\t\")[0])\n",
    "        idx = item.split(\"\\t\")[0].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        content = item.split(\"\\t\")[1].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        if content == \"true\":\n",
    "            content = 1\n",
    "        else:\n",
    "            content = 0\n",
    "        lab_dic_old[idx] = content\n",
    "print(lab_dic_old[\"0000002\"],len(lab_dic_old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 750000\n"
     ]
    }
   ],
   "source": [
    "# get labels from ground-truth-20181122.txt (new version data)\n",
    "lab_new = []\n",
    "lab_dic_new = {}\n",
    "with open(\"ground-truth-20181122.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for item in lines:\n",
    "        lab_new.append(item.split(\"\\t\")[0])\n",
    "        idx = item.split(\"\\t\")[0].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        content = item.split(\"\\t\")[1].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        if content == \"true\":\n",
    "            content = 1\n",
    "        else:\n",
    "            content = 0\n",
    "        lab_dic_new[idx] = content\n",
    "print(lab_dic_new[\"0000002\"],len(lab_dic_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "compare IDs of articles and labels \n",
    "import random\n",
    "count = 0\n",
    "for i in range(len(lab_new)):\n",
    "    if keys_new[i] != lab_new[i]:\n",
    "        count += 1\n",
    "print(count)\n",
    "\n",
    "import random\n",
    "count = 0\n",
    "for i in range(len(lab_old)):\n",
    "    if keys_old[i] != lab_old[i]:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656087\n",
      "['1488947', '0738958', '1069637', '0461249', '1289068']\n"
     ]
    }
   ],
   "source": [
    "# get intersection of new data and old data\n",
    "both = list(set(lab_new).intersection(set(lab_old)))\n",
    "print(len(both))\n",
    "print(both[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyuna to release new album by end of August Aug. 11 (UPI) — South Korean singer Hyuna will release a new album by the end of the month.  Hyuna’s agency, Cube Entertainment, said this week that the 25-year-old K-pop star is putting “the finishing touches” on the record, according to The Korea Herald.  The album was initially slated for release in September, but was pushed up because Hyuna “wanted to meet the fans as quickly as possible.” It is unknown if the record will be a single, EP or full-length album.  Osen reported Hyuna has picked a title song and will complete a new music video in “the near future.” The singer wrote and composed songs for the album, which will have a “sexy charm” that embodies the “hot summer.”  Hyuna shared a video July 28 of herself hard at work in the studio. The star tagged composer and songwriter Kim Tae-ho, whom she previously collaborated with on her EP A Talk.  @bicksancho  A post shared by Hyun Ah (@hyunah_aa) on Jul 28, 2017 at 4:00am PDT  Hyuna, a former member of the girl groups Wonder Girls and 4Minute, last released the EP A’wesome in August 2016. The album peaked at No. 2 on the Gaon Album Chart, and includes the singles “How’s This ” and “Freaky.”\n",
      "/n\n",
      "Hyuna to release new album by end of August Aug. 11 (UPI)   South Korean singer Hyuna will release a new album by the end of the month.  Hyuna s agency, Cube Entertainment, said this week that the 25-year-old K-pop star is putting  the finishing touches  on the record, according to The Korea Herald.  The album was initially slated for release in September, but was pushed up because Hyuna  wanted to meet the fans as quickly as possible.  It is unknown if the record will be a single, EP or full-length album.  Osen reported Hyuna has picked a title song and will complete a new music video in  the near future.  The singer wrote and composed songs for the album, which will have a  sexy charm  that embodies the  hot summer.   Hyuna shared a video July 28 of herself hard at work in the studio. The star tagged composer and songwriter Kim Tae-ho, whom she previously collaborated with on her EP A Talk.  @bicksancho  A post shared by Hyun Ah (@hyunah_aa) on Jul 28, 2017 at 4:00am PDT  Hyuna, a former member of the girl groups Wonder Girls and 4Minute, last released the EP A wesome in August 2016. The album peaked at No. 2 on the Gaon Album Chart, and includes the singles  How s This   and  Freaky. \n"
     ]
    }
   ],
   "source": [
    "print(con_dic_new[\"1326239\"])\n",
    "print(\"/n\")\n",
    "print(con_dic_old[\"1326239\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93913\n",
      "343913\n"
     ]
    }
   ],
   "source": [
    "# get different IDs of articels between new and old\n",
    "new = list(set(lab_new).difference(set(both))) \n",
    "print(len(new)) #the number of unique articles of new dataset\n",
    "old = list(set(lab_old).difference(set(both))) \n",
    "print(len(old))  #the number of unique articles of old dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "133786\n"
     ]
    }
   ],
   "source": [
    "true_lab = 0\n",
    "print(type(old))\n",
    "for aid in old:\n",
    "    true_lab += int(lab_dic_old[aid])\n",
    "print(true_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check total number of articles\n",
    "print(len(keys),len(con_dic))\n",
    "print(len(lab),len(lab_dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(con_dic[\"0000002\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output files, write articles of new dataset into train_dev_label.txt and train_dev_article.txt as training and developing datasets\n",
    "from random import shuffle\n",
    "label_file = open(\"train_dev_label.txt\", 'w')\n",
    "content_file = open(\"train_dev_article.txt\", 'w')\n",
    "shuffle(new)\n",
    "for item in new:\n",
    "    label_file.write(str(lab_dic_new[item])+\"\\n\")\n",
    "    content_file.write(con_dic_new[item]+\"\\n\")\n",
    "label_file.close()\n",
    "content_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289873\n",
      "366214\n"
     ]
    }
   ],
   "source": [
    "#output files, write articles of new dataset into train_dev_label.txt and train_dev_article.txt as training and developing datasets\n",
    "#write articles of new dataset into test_label.txt and test_article.txt\n",
    "#balanced class distribution in train_dev and test dataset\n",
    "import random\n",
    "label_file = open(\"train_dev_label.txt\", 'a')\n",
    "content_file = open(\"train_dev_article.txt\", 'a')\n",
    "label_test = open(\"test_label.txt\", 'w')\n",
    "content_test = open(\"test_article.txt\", 'w')\n",
    "lab_0 = 0\n",
    "lab_1 = 0\n",
    "shuffle(both)\n",
    "\n",
    "for item in both:\n",
    "    if lab_0<239873 and lab_dic_new[item] == 0:\n",
    "        lab_0 += 1\n",
    "        label_file.write(str(lab_dic_new[item])+\"\\n\")\n",
    "        content_file.write(con_dic_new[item]+\"\\n\")\n",
    "    elif lab_1<316214 and lab_dic_new[item] == 1:\n",
    "        lab_1 += 1\n",
    "        label_file.write(str(lab_dic_new[item])+\"\\n\")\n",
    "        content_file.write(con_dic_new[item]+\"\\n\")\n",
    "    elif lab_0>=239873 and lab_dic_new[item] == 0:\n",
    "        lab_0 += 1\n",
    "        label_test.write(str(lab_dic_new[item])+\"\\n\")\n",
    "        content_test.write(con_dic_new[item]+\"\\n\")\n",
    "    elif lab_1>=316214 and lab_dic_new[item] == 1:\n",
    "        lab_1 += 1\n",
    "        label_test.write(str(lab_dic_new[item])+\"\\n\")\n",
    "        content_test.write(con_dic_new[item]+\"\\n\")\n",
    "label_file.close()\n",
    "content_file.close()\n",
    "content_test.close()\n",
    "label_test.close()\n",
    "print(lab_0)\n",
    "print(lab_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output files, write articles of old dataset into train_dev_label.txt and train_dev_article.txt as training and developing datasets\n",
    "#write articles of new dataset into test_label.txt and test_article.txt\n",
    "#balanced class distribution in train_dev and test dataset\n",
    "import random\n",
    "label_file = open(\"train_dev_label.txt\", 'a')\n",
    "content_file = open(\"train_dev_article.txt\", 'a')\n",
    "lab_0 = 0\n",
    "lab_1 = 0\n",
    "shuffle(old)\n",
    "\n",
    "for item in old:\n",
    "    if lab_0<125000 and lab_dic_old[item] == 0:\n",
    "        lab_0 += 1\n",
    "        label_file.write(str(lab_dic_old[item])+\"\\n\")\n",
    "        content_file.write(con_dic_old[item]+\"\\n\")\n",
    "    elif lab_1<125000 and lab_dic_old[item] == 1:\n",
    "        lab_1 += 1\n",
    "        label_file.write(str(lab_dic_old[item])+\"\\n\")\n",
    "        content_file.write(con_dic_old[item]+\"\\n\")\n",
    "label_file.close()\n",
    "content_file.close()\n",
    "\n",
    "print(lab_0)\n",
    "print(lab_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900000\n"
     ]
    }
   ],
   "source": [
    "# check the length of train_dev dataset\n",
    "with open(\"train_dev_label.txt\",\"r\") as f: \n",
    "    lines = f.readlines()\n",
    "    print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare golden label dataset (byarticle-20181122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get articles-20180831.txt (old version data)\n",
    "keys_man = []\n",
    "con_dic_man = {}\n",
    "with open(\"articles-byarticle-20181122.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for i, item in enumerate(lines):\n",
    "        keys_man.append(item.split(\"\\t\")[0])\n",
    "        idx = item.split(\"\\t\")[0].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        content = item.split(\"\\t\")[1].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        con_dic_man[idx] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels from ground-truth-20180831.txt (old version data)\n",
    "lab_man = []\n",
    "lab_dic_man = {}\n",
    "with open(\"ground-truth-byarticle-20181122.xml\") as f:\n",
    "    lines = f.readlines()\n",
    "    for item in lines:\n",
    "        lab_man.append(item.split(\"\\t\")[0])\n",
    "        idx = item.split(\"\\t\")[0].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        content = item.split(\"\\t\")[1].replace(\"\\t\",\"\").replace(\"\\n\",\"\")\n",
    "        if content == \"true\":\n",
    "            content = 1\n",
    "        else:\n",
    "            content = 0\n",
    "        lab_dic_man[idx] = content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n",
      "238\n"
     ]
    }
   ],
   "source": [
    "#output files\n",
    "from random import shuffle\n",
    "shuffle(lab_man)\n",
    "label_file = open(\"byarticle_label.txt\", 'w')\n",
    "content_file = open(\"byarticle_article.txt\", 'w')\n",
    "lab_0 = 0\n",
    "lab_1 = 0\n",
    "\n",
    "for item in lab_man:\n",
    "    if lab_0<362 and lab_dic_man[item] == 0:\n",
    "        lab_0 += 1\n",
    "        label_file.write(str(lab_dic_man[item])+\"\\n\")\n",
    "        content_file.write(con_dic_man[item]+\"\\n\")\n",
    "    elif lab_dic_man[item] == 1:\n",
    "        lab_1 += 1\n",
    "        label_file.write(str(lab_dic_man[item])+\"\\n\")\n",
    "        content_file.write(con_dic_man[item]+\"\\n\")\n",
    "\n",
    "label_file.close()\n",
    "content_file.close()\n",
    "print(lab_0)\n",
    "print(lab_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
